version: 2
jobs:
  build:
    docker:
      - image: productml/spark-builder:0.32
    steps:
      - checkout
      - run:
          name: build
          command: sh build.sh
  deploy:
    docker:
      - image: productml/spark-builder:0.32
    steps:
      - checkout
      - run:
          name: init .pypirc
          command: |
            echo -e "[pypi]" >> ~/.pypirc
            echo -e "username = $PYPI_USER" >> ~/.pypirc
            echo -e "password = $PYPI_PASS" >> ~/.pypirc
      - run:
          name: deploy pypi
          command: |
            pipenv install --dev --ignore-pipfile
            pipenv run python setup.py sdist bdist_wheel
            pipenv run twine upload dist/*.gz
            pipenv run twine upload dist/*.whl
workflows:
  version: 2
  build_and_deploy:
    jobs:
      - build:
          filters:
            tags:
              only: /.*/
      - deploy:
          context: pypi
          requires:
            - build
          filters:
            tags:
              only: /[0-9]+(\.[0-9]+)*/
            branches:
              only: master
